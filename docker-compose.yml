version: '3.8'

services:
  redis:
    image: redis:latest
    container_name: redis_cache
    restart: always
    ports:
      - "6379:6379"

  rag-backend-api:
    build: .
    container_name: rag-backend-api
    restart: always
    user: "1000:1000"  # Host sistemle uyumlu user ID
    ports:
      - "8080:8080"
    volumes:
      - ./data/vectors:/app/data/vectors
      - ./data/uploaded_files:/app/data/uploaded_files
    depends_on:
      - redis
    environment:
      - STORAGE_TYPE=FileStorage
      - REDIS_CONNECTION_STRING=redis:6379
      - OLLAMA_HOST=http://ollama:11434
      - EMBEDDING_MODEL=nomic-embed-text
      - CHAT_MODEL=llama3.1:8b


  worker:
    build:
      context: ./python-worker
      dockerfile: Dockerfile
    container_name: rag_worker
    restart: always
    volumes:
      - ./data/vectors:/app/data/vectors
      - ./data/uploaded_files:/app/data/uploaded_files
    depends_on:
      - redis
      - rag-backend-api
      - ollama
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OLLAMA_HOST=http://ollama:11434
      - EMBEDDING_MODEL=nomic-embed-text
      - CHUNK_SIZE=1000
      - CHUNK_OVERLAP=200

  ollama:
    image: ollama/ollama:latest
    container_name: ollama_llm
    restart: always
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0


  frontend:
    build:
      context: ./frontend-ui
    container_name: rag_frontend
    restart: always
    ports:
      - "80:80"
    depends_on:
      - rag-backend-api

volumes:
  ollama_data: